% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/owl.R
\name{owl}
\alias{owl}
\title{Regularized Generalized Linear Models}
\usage{
owl(
  x,
  y,
  groups = NULL,
  family = c("gaussian", "binomial", "multinomial", "poisson"),
  penalty = c("slope", "group_slope"),
  solver = c("fista", "admm"),
  intercept = TRUE,
  standardize_features = TRUE,
  orthogonalize = TRUE,
  sigma = c("sequence", "estimate"),
  lambda = NULL,
  lambda_min_ratio = if (NROW(x) < NCOL(x)) 0.01 else 1e-04,
  n_sigma = 100,
  fdr = 0.2,
  screening_rule = c("none", "strong"),
  tol_dev_change = 1e-05,
  tol_dev_ratio = 0.999,
  max_passes = 1e+06,
  diagnostics = FALSE,
  verbosity = 0,
  ...
)
}
\arguments{
\item{x}{the feature matrix, which can be either a dense
matrix of the standard \emph{matrix} class, or a sparse matrix
inheriting from \link[Matrix:sparseMatrix]{Matrix::sparseMatrix} Data frames will
be converted to matrices internally.}

\item{y}{the response. For Gaussian models this must be numeric; for
binomial models, it can be a factor.}

\item{groups}{a vector of integers giving the group membership of each
feature (only applies to Group SLOPE)}

\item{family}{response type. See \strong{Families} for details.}

\item{penalty}{the regularization penalty to use. See \strong{Penalties} for
details.}

\item{solver}{the numerical solver to use. See \strong{Solvers} for details.}

\item{intercept}{whether to fit an intercept}

\item{standardize_features}{whether to standardize features (predictors)}

\item{orthogonalize}{whether \code{x} should be orthogonalized. Note that
setting this to TRUE when \code{x} is sparse will through an error. (only
applies to Group SLOPE)}

\item{sigma}{noise estimate (only applies to SLOPE and Group SLOPE)}

\item{lambda}{either a character vector indicating the method used
to construct the lambda path or the a vector or matrix}

\item{lambda_min_ratio}{smallest value for \code{lambda} as a fraction of
\code{lambda_max}}

\item{n_sigma}{length of regularization path}

\item{fdr}{target false discovery rate (only applies to SLOPE and
Group SLOPE)}

\item{screening_rule}{type of screening rule to use}

\item{tol_dev_change}{the regularization path is stopped if the
fractional change in deviance falls below this value. Note that this is
automatically set to 0 if a sigma is manually entered}

\item{tol_dev_ratio}{the regularization path is stopped if the
deviance ratio
\eqn{1 - \mathrm{deviance}/\mathrm{(null-deviance)}}{1 - deviance/(null deviance)}
is above this threshold}

\item{max_passes}{maximum number of passes for optimizer}

\item{diagnostics}{should diagnostics be saved for the model fit (timings,
primal and dual objectives, and infeasibility)}

\item{verbosity}{level of verbosity for displaying output from the
program. Setting this to 1 displays information on the path level,
while setting it to 2 displays information also from inside the solver.}

\item{...}{arguments passed on to the solver (see \code{\link[=FISTA]{FISTA()}}, and \code{\link[=ADMM]{ADMM()}})}
}
\value{
An object of class \code{"Owl"} with the following slots:
\item{coefficients}{
a three-dimensional array of the coefficients from the
model fit, including the intercept if it was fit.
There is one row for each coefficient, one column
for each target (dependent variable), and
one slice for each penalty.
}
\item{nonzeros}{
a three-dimensional boolean array indicating whether a
coefficient was zero or not
}
\item{lambda}{
the lambda vector that when multiplied by a value in \code{sigma}
gives the penalty vector at that point along the regularization
path
}
\item{sigma}{the vector of sigma, indicating the scale of the lambda vector}
\item{class_names}{
a character vector giving the names of the classes for binomial and
multinomial families
}
\item{passes}{the number of passes the solver took at each path}
\item{violations}{the number of violations of the screening rule}
\item{active_sets}{
a list where each element indicates the indices of the
coefficients that were active at that point in the regularization path
}
\item{diagnostics}{
a \code{data.frame} of objective values for the primal and dual problems, as
well as a measure of the infeasibility, time, and iteration. Only
available if \code{diagnostics = TRUE} in the call to \code{\link[=owl]{owl()}}.
}
\item{call}{the call used for fitting the model}
}
\description{
This functions fits a generalized linear model (GLM) using efficient
optimization routines suitable to big data problems.
}
\details{
The objective for each model is simply the loss function for
each family plus a penalty term.
}
\section{Families}{


\strong{Gaussian}

The Gaussian model (Ordinary Least Squares) minimizes the following
objective.

\deqn{
  ||y - X\beta||_2^2
}{
  ||y - X\beta||_2^2
}

\strong{Binomial}

The binomial model (logistic regression) has the following objective.

\deqn{
  \sum_{i=1}^n \log\left(1+ \exp\left(- y_i \left(x_i^T\beta + \alpha \right) \right) \right)
}{
  \sum log(1+ exp(- y_i x_i^T \beta))
}

\strong{Poisson}

In poisson regression, we use the following objective.

\deqn{
  -\sum_{i=1}^n \left(y_i\left(x_i^T\beta + \alpha\right) - \exp\left(x_i^T\beta + \alpha\right)\right)
}{
  -\sum (y_i(x_i^T\beta + \alpha) - exp(x_i^T\beta + \alpha))
}

\strong{Multinomial}

In multinomial regression, we use the following objective.

\deqn{
  -\sum_{i=1}^n\left( \sum_{k=1}^m y_{ik}(x_i^T\beta_k + \alpha_k)
                     - \log\sum_{k=1}^m \exp(x_i^T\beta_k + \alpha_k) \right)
}{
  -\sum(y_ik(x_i^T\beta_k + \alpha_k) - log(\sum exp(x_i^T\beta_k + \alpha_k)))
}
}

\section{Penalties}{

Models fit by \code{\link[=owl]{owl()}} can be regularized via several
penalties.

\strong{SLOPE}

SLOPE (Sorted L-One Penalized Estimation) is an extension of the Lasso.
Unlike the latter, however, SLOPE uses a non-increasing
sequence of \eqn{\lambda}---one
for each coefficient. The penalty term looks like

\deqn{
  \sigma \sum_{i=j}^p \lambda_j |\beta|_{(j)}
}{
  \sigma \sum \lambda |\beta|(j)
}

\strong{Group SLOPE}

Group SLOPE is an extension of Group LASSO. It applies the following
penalty

\deqn{
  J_\lambda(\beta) = \sum_{j=1}^p \lambda_j |W||\beta||_{I,X}|_{(j)}
}{
  J_\lambda(\beta) = \sum \lambda_j |W||\beta||_{I,X}|_(j)
}
}

\examples{

# Gaussian response

fit <- owl(abalone$x, abalone$y)

# Binomial response

fit <- owl(heart$x, heart$y, family = "binomial")

# Poisson response

fit <- owl(abalone$x, abalone$y, family = "poisson")

}
\seealso{
\code{\link[=plot.Owl]{plot.Owl()}}, \code{\link[=plotDiagnostics]{plotDiagnostics()}}, \code{\link[=score]{score()}}, \code{\link[=predict.Owl]{predict.Owl()}},
\code{\link[=trainOwl]{trainOwl()}}
}
